# Run the `kubectl top pods` command to get the CPU usage for each pod in the cluster
$pod_cpu_usage = kubectl top pods --all-namespaces --containers | ConvertFrom-Csv | Select-Object -Property namespace, name, cpu

# Group the pod CPU usage by deployment and sum the CPU usage for each deployment
$deployment_cpu_usage = $pod_cpu_usage | ForEach-Object { "$($_.namespace)/$($_.name)".Split('-')[0] } | Group-Object | Select-Object -Property Name, @{ Name='Cpu'; Expression={ ($_.Group.cpu | Measure-Object -Sum).Sum } }

# Sort the deployments by CPU usage and get the top 5
$sorted_deployments = $deployment_cpu_usage | Sort-Object -Property Cpu -Descending | Select-Object -First 5

# Print the list of top 5 deployments by CPU usage
foreach ($deployment in $sorted_deployments) {
    $deployment_name = $deployment.Name
    $cpu_usage = $deployment.Cpu
    Write-Host "$deployment_name: $cpu_usage"
}


az redis show --name <redis-name> --resource-group <resource-group-name> --ids $(az redis show --name <redis-name> --resource-group <resource-group-name> --query id --output tsv)/diagnostics \
--query 'cacheMemoryUsage,cacheCPUUtilization,activeClientConnections'

-----

from azure.monitor.query import MetricsQueryClient
from azure.identity import DefaultAzureCredential

# Replace with your Azure subscription ID and Azure Cache for Redis resource ID
subscription_id = 'your-subscription-id'
resource_id = '/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.Cache/Redis/{cache_name}'

# Create an instance of the MetricsQueryClient class
credential = DefaultAzureCredential()
metrics_client = MetricsQueryClient(credential)


----------

import subprocess
import re

# Define the command to retrieve the CPU usage of all pods in all namespaces
cmd = ["kubectl", "top", "pod", "--all-namespaces"]

# Run the command and capture the output
output = subprocess.check_output(cmd).decode()

# Parse the output and group the CPU usage by app
cpu_usage_by_app = {}
lines = output.strip().split('\n')
for line in lines[1:]:
    cols = re.split('\s+', line.strip())
    app = cols[1].split('-')[0] # Extract the app name from the pod name
    cpu_usage = cols[2]
    if app not in cpu_usage_by_app:
        cpu_usage_by_app[app] = 0
    cpu_usage_by_app[app] += int(cpu_usage)

# Print the total CPU usage for each app
for app, cpu_usage in cpu_usage_by_app.items():
    print(f"{app}: {cpu_usage}m")


# Define the metrics to retrieve
metrics = [
    'Server CPU',
    'Memory Usage',
    'Connected Clients'
]

# Define the time range for the metrics query (last 5 minutes in this example)
from_date = datetime.datetime.now() - datetime.timedelta(minutes=5)
to_date = datetime.datetime.now()

# Execute the metrics query and retrieve the results
result = metrics_client.query(resource_id, metrics, from_date, to_date, timespan=None, granularity='PT1M')

# Process the metrics data
for metric in result.metrics:
    print('Metric:', metric.name.localized_value)
    for time_series in metric.timeseries:
        print('Time Series:')
        for data_point in time_series.data:
            print('Timestamp:', data_point.time_stamp)
            print('Value:', data_point.average)

--------------------------------
---------------

# Get the database ID for your Azure Cosmos DB account
database_id=$(az cosmosdb show --name <cosmosdb-account-name> --resource-group <resource-group> --query "id")

# Get the list of collections in your Azure Cosmos DB account
collections=$(az cosmosdb collection list --account-name <cosmosdb-account-name> --db-name <database-name> --query "[].id" -o tsv)

# Loop through each collection and get its RU consumption metrics
for collection in $collections
do
    # Get the collection ID for the current collection
    collection_id=$(az cosmosdb collection show --collection-name $collection --db-name <database-name> --account-name <cosmosdb-account-name> --query "resource.id")

    # Get the RU consumption metrics for the current collection
    az monitor metrics list --resource $database_id/collections/$collection_id --metric "Total Request Units Consumed" --interval PT1H --start-time $(date +%Y-%m-%dT%H:%MZ -d '-1 hour') --end-time $(date +%Y-%m-%dT%H:%MZ) --aggregation Average --query "{Collection: dimensions[0].value, 'RU Consumption': average}" -o table
done


--------------
from kubernetes import client, config

# Load the Kubernetes configuration
config.load_kube_config()

# Create the Kubernetes API clients
v1 = client.CoreV1Api()
metrics_api = client.MetricsV1beta1Api()
apps_api = client.AppsV1Api()

# Set the deployment name and namespace
deploy_name = "<your-deployment-name>"
namespace = "<your-namespace>"

# Get the deployment object
deploy = apps_api.read_namespaced_deployment(deploy_name, namespace=namespace)

# Get the labels for the deployment
labels = deploy.spec.selector.match_labels

# Get the pods for the deployment
pods = v1.list_namespaced_pod(namespace=namespace, label_selector=','.join([f"{k}={v}" for k, v in labels.items()]))

# Get the CPU and memory usage metrics for each pod
for pod in pods.items:
    pod_name = pod.metadata.name
    pod_metrics = metrics_api.list_namespaced_pod_metrics(namespace=namespace, label_selector=','.join([f"{k}={v}" for k, v in labels.items()]), field_selector=f"metadata.name={pod_name}")

    # Print the CPU and memory usage metrics for the pod
    print(f"Metrics for pod {pod_name}:")
    for container in pod_metrics.items[0].containers:
        print(f" - Container {container.name}: CPU usage {container.usage['cpu']}, memory usage {container.usage['memory']}")


---------------


import subprocess
import re

# Define the command to retrieve the CPU usage of all pods in all namespaces
cmd = ["kubectl", "top", "pod", "--all-namespaces"]

# Run the command and capture the output
output = subprocess.check_output(cmd).decode()

# Parse the output and group the CPU usage by app
cpu_usage_by_app = {}
lines = output.strip().split('\n')
for line in lines[1:]:
    cols = re.split('\s+', line.strip())
    app = cols[1].split('-')[0] # Extract the app name from the pod name
    cpu_usage = cols[2]
    if app not in cpu_usage_by_app:
        cpu_usage_by_app[app] = 0
    cpu_usage_by_app[app] += int(cpu_usage)

# Print the total CPU usage for each app
for app, cpu_usage in cpu_usage_by_app.items():
    print(f"{app}: {cpu_usage}m")
    


kubectl get pods -o 'custom-columns=NAME:.metadata.name,CPU:.spec.containers[*].usage.cpu,MEMORY:.spec.containers[*].usage.memory,ANNOTATIONS:.metadata.annotations' | kubectl top pods

---------------------

import pandas as pd

# Create a data frame
df = pd.DataFrame({
    'Class Name': ['AB-CD-1-1', 'AB-CD-1-2', 'AB-CD-1-3', 'EF-GH-1-1', 'EF-GH-1-2', 'EF-GH-1-3'],
    'Number of Students': [20, 30, 40, 50, 60, 70]
})

# Extract the class name without the last two substrings
df['Number of Students'] = df['Number of Students'].str.rstrip('s').astype(int)
df['Class'] = df['Class Name'].str.split('-', n=2).str[:2].str.join('-')

df['Class'] = df['Class Name'].apply(lambda x: '-'.join(x.split('-')[:-2]))


# Group the data by the class name and sum the number of students
df_sum = df.groupby('Class')['Number of Students'].sum()

# Print the resulting data frame
print(df_sum)

df_sum.to_csv('output.txt', header=True, index=True, sep='\t')

----------------
Pods Scaled more than 4

from kubernetes import client, config

# Load the Kubernetes configuration
config.load_kube_config()

# Create a Kubernetes API client
api_client = client.AppsV1Api()

# Get all namespaces
namespaces = api_client.list_namespace()

# Loop through each namespace
for namespace in namespaces.items:
    namespace_name = namespace.metadata.name
    print("Namespace:", namespace_name)

    # Get all deployments in the namespace
    deployments = api_client.list_namespaced_deployment(namespace_name)

    # Loop through each deployment
    for deployment in deployments.items:
        deployment_name = deployment.metadata.name
        deployment_replicas = deployment.spec.replicas
        if deployment_replicas and deployment_replicas > 4:
            print(f"Deployment {deployment_name} in namespace {namespace_name} has {deployment_replicas} replicas.")


az monitor metrics list --resource <resource-id> --metric <metric-name> --interval PT1M --start-time "$(date -u +%Y-%m-%dT%H:%M:%SZ --date '-10 minutes')" --end-time "$(date -u +%Y-%m-%dT%H:%M:%SZ)" --output table --query "value[].timeseries[].data[].{Time: strftime('%Y-%m-%d %H:%M:%S', gmtime(./time/1000 + (5 * 3600))), Value: average}"


------------------


import pandas as pd
import pytz
from datetime import datetime

# Load the data into a Pandas DataFrame
df = pd.read_csv("data.csv")

# Define a function to convert UTC timestamps to IST
def convert_to_ist(timestamp):
    tz_utc = pytz.timezone('UTC')
    tz_ist = pytz.timezone('Asia/Kolkata')
    dt_utc = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
    dt_utc = tz_utc.localize(dt_utc)
    dt_ist = dt_utc.astimezone(tz_ist)
    return dt_ist.strftime('%Y-%m-%d %H:%M:%S')

# Replace the UTC timestamp column with the corresponding IST timestamps
df['timestamp'] = df['timestamp'].apply(lambda x: convert_to_ist(x))

# Print the updated DataFrame
print(df)


with open("output.txt", "w") as f:
    f.write(df.to_string(index=False))
--------------

from bs4 import BeautifulSoup
import pandas as pd

# Assume we have an existing HTML document stored in the 'html_document' variable

# Parse the HTML document using BeautifulSoup
soup = BeautifulSoup(html_document, 'html.parser')

# Find the <body> tag in the HTML document
body_tag = soup.find('body')

# Create a pandas dataframe
df = pd.DataFrame({
    'Full Name': ['Vincent Williamson', 'John Doe'],
    'Age': [31, 42],
    'Job Title': ['iOS Developer', 'Data Scientist'],
    'Location': ['Washington', 'New York']
})

# Generate the dynamic HTML code as described in the previous answer
header_row = ''.join(['<div class="cell">{}</div>'.format(col_name) for col_name in df.columns])
header_html = '<div class="row header">{}</div>'.format(header_row)
data_rows = []
for index, row in df.iterrows():
    data_row = ''.join(['<div class="cell" data-title="{}">{}</div>'.format(col_name, row[col_name]) for col_name in df.columns])
    data_rows.append('<div class="row">{}</div>'.format(data_row))
data_html = ''.join(data_rows)
html_code = '<div class="limiter"><div class="container-table100"><div class="wrap-table100"><div class="table">{}</div></div></div></div>'.format(header_html + data_html)

# Convert the dynamic HTML code into a BeautifulSoup object
dynamic_soup = BeautifulSoup(html_code, 'html.parser')

# Insert the dynamic HTML code into the <body> tag
body_tag.append(dynamic_soup)

# Convert the modified HTML document back into a string
modified_html_document = str(soup)


--------------


from selenium import webdriver

# Set the path to your local HTML file
html_file_path = "/path/to/local/file.html"

# Configure the webdriver to use the Chrome browser
driver = webdriver.Chrome()

# Load the local HTML file in the browser
driver.get("file://" + html_file_path)

# Wait for the page to fully load
driver.implicitly_wait(10)

# Get the height of the entire webpage
total_height = driver.execute_script("return document.body.scrollHeight")

# Set the width of the screenshot to match the width of the browser window
screenshot_width = driver.execute_script("return document.body.offsetWidth")

# Set the height of the screenshot to match the height of the entire webpage
driver.set_window_size(screenshot_width, total_height)
# Take a screenshot of the webpage and save it as a PNG file
driver.save_screenshot("screenshot.png")

# Close the browser
driver.quit()


https://github.com/kubernetes-client/python


$_.Split("`t")[0] + "=" + $_.Split("`t")[1]

----------------------

 # App Configuration task
 
 
# Set the variables for the Azure App Configuration and Kubernetes ConfigMap
$AppConfigEndpoint = "https://<app-config-name>.azconfig.io"
$AppConfigKey = "<app-config-key>"
$ConfigMapName = "<configmap-name>"
$Namespace = "<namespace>"

# Fetch the key-value pairs from Azure App Configuration using the Azure CLI
$KeyValuePairs = az appconfig kv list --endpoint $AppConfigEndpoint --key $AppConfigKey --all | ConvertFrom-Json | foreach { $_.name + "=" + $_.value }

# Build the data string for the ConfigMap using the key-value pairs
$DataString = ""
foreach ($KeyValuePair in $KeyValuePairs) {
    $DataString += "`n$KeyValuePair"
}

# Remove the first newline character from the data string
$DataString = $DataString.TrimStart("`n")

# Update the ConfigMap with the new data using kubectl
kubectl patch configmap $ConfigMapName -n $Namespace --type merge --patch "`"{\"data\":{\"$DataString\"}}`""

# Verify that the ConfigMap was updated
kubectl get configmap $ConfigMapName -n $Namespace
